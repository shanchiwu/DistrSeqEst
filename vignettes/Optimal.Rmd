---
title: "Customize Optimal Design"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Customize Optimal Design}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(DistrSeqEst)
```


## Custom Sample Selection Strategies

In `DistrSeqEst`, adaptive sequential sampling is governed by a customizable selection function. This function determines which data point to label next, from the pool of currently unlabeled observations.

The framework supports arbitrary user-defined strategies. Users simply need to write a function with a standardized signature (see below), and pass its name (as a string) to the `adaptive` argument in `seq_ana`.

To define a new selection strategy, users can implement an S3 method following the naming convention:
```{r}
design_select.mystrategy <- function(method, X, w, labeled_id, unlabeled_id, ...) {
  # Custom logic here
  return(unlabeled_id[1])  # Example: always select first
}
```

Then, register it via:

```{r, eval=FALSE}
fit <- seq_ana(..., adaptive = "mystrategy", ...)
```


The following demonstrates how to define such a function. The example shown below, `design_select.min`, is intentionally naive: it always selects the first available unlabeled observation. While this strategy lacks theoretical justification, it reflects a scenario commonly encountered in online learning or real-time data acquisition, where data arrives in a time-ordered manner and must be consumed sequentially.

```{r}
# A minimal custom sampling strategy: always pick the first available index
design_select.min <- function(method, X, w, labeled_id, unlabeled_id, ...) {
  return(unlabeled_id[1])
}
```

The function must return the index (or indices) of the next data point(s) to be selected from the `unlabeled_id` pool. The arguments provided allow access to current covariates `X`, weights `w`, and index sets for labeled and unlabeled data. You may also pass additional parameters using `...`.

You can register and activate this strategy by setting `adaptive = "min"` when calling `seq_ana`.

More sophisticated strategies can make use of model predictions, uncertainty quantification, or information-based utilities - all by modifying this function accordingly.


# Generate the data

We simulate synthetic data based on a logistic regression model. The regression coefficients are specified in vector `b`. The covariates are generated from a standard normal distribution, and the binary outcome `Y` is generated according to the logistic model.
```{r}
b = c(-2,2,1,1,0)

gen_data = function(N, b){
  p = length(b)
  X = cbind(rep(1,N), matrix(rnorm(n=N*(p-1)), ncol = p-1))
  Xb = X %*% b

  p1 = 1 / (1+exp(-Xb))
  Y = rbinom(n=N, size=1, prob=p1)

  data = data.frame(X,Y)
}

set.seed(1)
df = gen_data(10000,b)
```


# Fit model

We now run the sequential analysis using the `seq_ana` function. The function proceeds to sequentially sample from the data based on the defined selection strategy until the stopping rule is triggered.
```{r}
set.seed(1)
fit = seq_ana(df, interest = Y ~ X1 + X2 + X3 -1, nuisance = Y ~ . -1,
              init_N = 100, d1 = 0.3, alpha = 0.05,
              model = "glm", fit_args = list(family = binomial()),
              alternative = "two.sided", adaptive = "min",
              verbose = 3, max_try = 1000)
summary(fit)
```


Check the data that is ordered. First 100 is random due to random initialization.
```{r}
fit$labeled_id[1:200]
```

## Another example

We define another custom sampling function `design_select.uncertain`, which performs classical uncertainty sampling: it selects the point whose predicted probability is closest to 0.5 â€” the region of maximum uncertainty under a Bernoulli model.

This design is common in active learning literature and is particularly useful when the model is used iteratively to reduce prediction variance.

```{r}
design_select.uncertain <- function(method, X, w, labeled_id, unlabeled_id, fit) {
  # Predict probabilities for unlabeled data
  eta <- X[unlabeled_id, , drop = FALSE] %*% fit$coefficients
  prob <- binomial()$linkinv(eta)  # same as plogis(eta)

  # Compute uncertainty as distance from 0.5 (maximum uncertainty)
  uncertainty <- -abs(prob - 0.5)  # Negative for descending sort

  # Select the most uncertain point
  selected_index <- which.max(uncertainty)
  return(unlabeled_id[selected_index])
}
```

```{r}
set.seed(1)
fit = seq_ana(df, interest = Y ~ X1 + X2 + X3 -1, nuisance = Y ~ . -1,
              init_N = 100, d1 = 0.3, alpha = 0.05,
              model = "glm", fit_args = list(family = binomial()),
              alternative = "two.sided", adaptive = "uncertain",
              verbose = 3, max_try = 1000)
summary(fit)
```

This vignette demonstrates how to integrate a user-defined adaptive sampling strategy into the `DistrSeqEst` framework. While we used a simple strategy for illustrative purposes, the design interface allows for flexible extensions based on theoretical criteria, empirical uncertainty, or machine learning-based utility scores.

This extensibility enables the development of efficient and intelligent sequential analysis pipelines in various domains including clinical trials, online A/B testing, and adaptive survey sampling.

